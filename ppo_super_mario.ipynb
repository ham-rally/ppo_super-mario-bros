{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppo_super_mario.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWQRmaYZo5DlGlW6dz+269",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unknown-yuser/ppo_super-mario-bros/blob/main/ppo_super_mario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU_tc1LRhvDg"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# GPU情報を表示\n",
        "nvidia-smi\n",
        "\n",
        "# スーパーマリオブラザーズの環境を用意\n",
        "pip install -q nes-py gym-super-mario-bros\n",
        "\n",
        "# 強化学習ライブラリをインストール\n",
        "pip install -q stable-baselines3[extra]\n",
        "\n",
        "# 学習結果の描画\n",
        "apt-get install -qq ffmpeg freeglut3-dev xvfb\n",
        "pip install -q pyglet pyvirtualdisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx81JVD-uIMg"
      },
      "source": [
        "#@title マリオブラザーズ環境\n",
        "\n",
        "WORLD=1#@param {type:'integer'}\n",
        "STAGE=1#@param {type:'integer'}\n",
        "ACTION_TYPE_STR = \"SIMPLE_MOVEMENT\" #@param [\"RIGHT_ONLY\", \"SIMPLE_MOVEMENT\", \"COMPLEX_MOVEMENT\"]\n",
        "\n",
        "MARIO_ENV=f'SuperMarioBros-{WORLD}-{STAGE}-v0'\n",
        "\n",
        "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "\n",
        "ACTION_TYPE_MAP = {\n",
        "    'RIGHT_ONLY': RIGHT_ONLY,\n",
        "    'SIMPLE_MOVEMENT': SIMPLE_MOVEMENT,\n",
        "    'COMPLEX_MOVEMENT': COMPLEX_MOVEMENT\n",
        "}\n",
        "\n",
        "# getter\n",
        "def mario_action():\n",
        "    return ACTION_TYPE_MAP[ACTION_TYPE_STR]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 学習/テスト 設定\n",
        "\n",
        "OUTPUT_DIR='super_mario_bros/'#@param {type:'string'}\n",
        "VIDEO_DIR='video/' #@param {type:'string'}\n",
        "VIDEO_NAME_PREFIX=\"mario_play\" #@param {type:'string'}\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.environ['OUTPUT_DIR'] = OUTPUT_DIR\n",
        "\n",
        "FIRST_LEARNING_RATE = 0.0002 #@param {type:\"number\"}\n",
        "LAST_LEARNING_RATE = 0.00003 #@param {type:\"number\"}\n",
        "GAMMA = 0.95 #@param {type:\"slider\", min:0.8, max:1, step:0.01}\n",
        "LAMBDA = 0.84 #@param {type:\"slider\", min:0.8, max:1, step:0.01}\n",
        "REWARD_THRESHOLD = 3000 #@param {type:\"number\"}\n",
        "\n",
        "MAX_STEPS = 600000 #@param {type:\"integer\"}\n",
        "EVAL_INTERVAL = 40000 #@param {type:\"integer\"}\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def best_model_path():\n",
        "    return os.path.join(OUTPUT_DIR, \"best_model\")"
      ],
      "metadata": {
        "id": "9MN8SlISUuZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv, WarpFrame\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "def mario_env(train:bool = False) -> gym.Env:\n",
        "    e = gym_super_mario_bros.make(MARIO_ENV)\n",
        "    e = JoypadSpace(e, mario_action())\n",
        "    e = MaxAndSkipEnv(e, skip=4)\n",
        "    e = WarpFrame(e, width=84, height=84)\n",
        "    if train:\n",
        "        return Monitor(e, OUTPUT_DIR)\n",
        "    else:\n",
        "        return e"
      ],
      "metadata": {
        "id": "NeXd3hyVUmSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAuF0rWildJu"
      },
      "source": [
        "from stable_baselines3 import PPO\n",
        "from typing import Callable\n",
        "\n",
        "def learning_rate_schedule(first_value: float, last_value: float) -> Callable[[float], float]:\n",
        "    def func(progress_remaining: float):\n",
        "        return last_value + (first_value - last_value) * progress_remaining\n",
        "    return func\n",
        "\n",
        "player = PPO(\n",
        "    \"CnnPolicy\",\n",
        "    mario_env(train=True), \n",
        "    learning_rate=learning_rate_schedule(FIRST_LEARNING_RATE, LAST_LEARNING_RATE),\n",
        "    batch_size=32,\n",
        "    gamma=GAMMA,\n",
        "    gae_lambda=LAMBDA,\n",
        "    create_eval_env=True,\n",
        "    ent_coef=0.02,\n",
        "    vf_coef=1.0,\n",
        "    tensorboard_log=OUTPUT_DIR,\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?PPO"
      ],
      "metadata": {
        "id": "xik7nXfu2GGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPPRwuNC1bbe"
      },
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "\n",
        "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=REWARD_THRESHOLD, verbose=1)\n",
        "eval_callback = EvalCallback(\n",
        "    mario_env(train=True),\n",
        "    callback_on_new_best=callback_on_best,\n",
        "    eval_freq=EVAL_INTERVAL,\n",
        "    best_model_save_path=best_model_path(),\n",
        "    deterministic=False,\n",
        "    verbose=1)\n",
        "\n",
        "%time player.learn(total_timesteps=MAX_STEPS, callback=eval_callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIsBbEtjvXO-"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $OUTPUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_best_player():\n",
        "    return PPO.load(os.path.join(best_model_path(), 'best_model'))"
      ],
      "metadata": {
        "id": "Vlrvi-Xk0STU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuIIKOrWi5yZ"
      },
      "source": [
        "from gym.wrappers import RecordVideo\n",
        "\n",
        "def record_video(model: BaseAlgorithm, name_prefix:str, video_folder: str):\n",
        "    \"\"\"\n",
        "    :param model: (RL model)\n",
        "    :param video_folder: (str)\n",
        "    \"\"\"\n",
        "    eval_env = RecordVideo(\n",
        "        mario_env(),\n",
        "        video_length=5000,\n",
        "        video_folder=video_folder,\n",
        "        name_prefix=name_prefix\n",
        "    )\n",
        "    \n",
        "    obs = eval_env.reset()\n",
        "    cnt_terminal_reached = 0\n",
        "    max_cnt_terminal_reached = 10\n",
        "    while True:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, done, _ = eval_env.step(action)\n",
        "        if done:\n",
        "            cnt_terminal_reached = cnt_terminal_reached + 1\n",
        "            eval_env.reset()\n",
        "            if cnt_terminal_reached >= max_cnt_terminal_reached:\n",
        "                eval_env.close_video_recorder()\n",
        "                break\n",
        "\n",
        "record_video(load_best_player(), VIDEO_NAME_PREFIX, VIDEO_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIPew4ypdne"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "from IPython import display as ipdisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "# from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "def show_video(name_prefix:str, video_folder: str):\n",
        "    \"\"\"\n",
        "    Reference from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param name_prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    :param video_folder: (str) Path to the folder containing videos\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_folder).glob('{}*.mp4'.format(name_prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay\n",
        "        loop controls style=\"height: 400px;\">\n",
        "        <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "        </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipdisplay.display(ipdisplay.HTML(data=\"<br>\".join(html)))\n",
        "\n",
        "show_video(VIDEO_NAME_PREFIX, VIDEO_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}